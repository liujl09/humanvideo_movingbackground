
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>DreaMoving</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

        <!--FACEBOOK-->
    <meta property="og:image" content="">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="682">
    <meta property="og:image:height" content="682">
    <meta property="og:type" content="website" />
    <meta property="og:url" content=""/>
    <meta property="og:title" content="DreaMoving" />
    <meta property="og:description" content="Project page for DreaMoving." />

        <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="DreaMoving" />
    <meta name="twitter:description" content="Project page for DreaMoving." />
    <meta name="twitter:image" content="" />


    <!--<link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
    <!-- <link rel="icon" type="image/png" href="img/seal_icon.png"> -->
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <br>
    <div class="container" id="main" style="width: 85%;">
    <!-- <div class="container" id="main"> -->
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b></b>Disentangling Foreground and Background Motion <br>for Enhanced Realism in Human Video Generation</br>
                <!-- <small>
                    Technical Report
                </small> -->
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <!-- <a href="">
                            DreaMoving Team
                        </a> -->
                        <a href="">Jinlin Liu</a>&emsp;
                        <a href="">Kai Yu</a>&emsp;
                        <a href="">Mengyang Feng</a>&emsp;
                        <a href="">Xiefan Guo</a>&emsp;
                        <a href="">Miaomiao Cui</a>&emsp;

                        <!-- <p>Mengyang Feng, Jinlin Liu, Kai Yu, Yuan Yao, Zheng Hui, Xiefan Guo, Miaomiao Cui, Peiran Ren, Xuansong Xie<br>Alibaba Group</p> -->
                        <br><p>Alibaba Group</p>
                    </li>
                </ul>
            </div>
        </div>
        
        
        <div class="row">
            <div class="col-md-8 col-md-offset-2">             
                <table border="0" cellspacing="0" cellpadding="0" align="center" width="48%">
                    <tr>
                        <td align="center" valign="middle" width="20%">
                            <a href="https://arxiv.org/abs/2312.05107" style="text-decoration: none;">
                                <image src="assets/paper_image.jpg" height="60px" style="margin: 0px 0px 10px 0px;">
                                <p>Paper</p>
                            </a>
                        </td>
                    </tr>
                </table>
            </div>
        </div>

        <br>
        
        <div class="row">
            <div class="col-md-8 col-md-offset-2">            
                <table border="0" cellspacing="0" cellpadding="0" align="center">
                    <tr>
                        <td align="center" valign="middle">
                            <video id="v0" width="99%" autoplay loop muted controls>
                                <source src="assets/videos/github_clip.mp4" type="video/mp4" />
                            </video>
                        </td>
                    </tr>
                </table>
                <p style="font-size: 18px;" align="center">
                    Our approach allows for the generation of realistic human actions against backgrounds that are in motion, departing from the conventional static backdrop.
                </p>   
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    <strong>Abstract</strong>
                </h3>
                <p class="text-justify">
                    Recent progress in human video synthesis uses stable diffusion models for high-quality video creation. However, most methods animate only the foreground based on pose data, leaving backgrounds static, unlike real-life videos where backgrounds move with the action. Our solution learns both foreground and background motion separately, using pose-based animation for people and sparse tracking points for backgrounds, reflecting their natural interaction. Trained on real videos with this advanced motion capture, our model outputs coherent foreground and background movement. For longer videos, we generate clips sequentially, adding global features at each stage and connecting clips via the final frame of the previous one to preserve continuity, also infusing the reference image's features to prevent color inconsistencies. Tests prove our method excels at creating videos that blend foreground actions with reactive backgrounds more effectively than previous approaches.
                </p>
            </div>
        </div>


        <div class="row"> 
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    <strong>Architecture</strong>
                </h3>
                <p class="text-justify">
                    Our method separates foreground and background motion, using pose estimation for foreground and sparse tracking points for background. This enables realistic human actions with dynamic backgrounds. We also introduce an advanced pipeline for creating long videos free from accumulated errors, achieved through clever conditioning and global feature use, ensuring coherent and consistent extended clips.
                </p>
                <br>
                <image width="80%" src="assets/pipeline.png" class="img-responsive" alt="overview" style="margin:auto"><br>
            </div>
        </div>

        <div class="row"> 
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    <strong>Video</strong>
                </h3>
                <table border="0" cellspacing="0" cellpadding="0" align="center">
                    <tr>
                        <td align="center" valign="middle">
                            <video id="v0" width="99%" autoplay loop muted controls>
                                <source src="assets/videos/github_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                    </tr>
                </table>
            </div>
        </div>


        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
            <textarea id="bibtex" class="form-control" readonly>
            @article{feng2023dreamoving,
                title={DreaMoving: A Human Video Generation Framework based on Diffusion Models},
                author={Mengyang Feng, Jinlin Liu, Kai Yu, Yuan Yao, Zheng Hui, Xiefan Guo, Xianhui Lin, Haolan Xue,
                        Chen Shi, Xiaowen Li, Aojie Li, Xiaoyang Kang, Biwen Lei, Miaomiao Cui, Peiran Ren, Xuansong Xie},
                journal={arXiv},
                year={2023}
            }</textarea>
          </div>
        </div> -->


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                The website template was borrowed from <a href="http://mgharbi.com/">MichaÃ«l Gharbi</a> and <a href="https://jonbarron.info/mipnerf/">Mip-NeRF</a>.
                </p>
            </div>
        </div>

    </div>  
    <br><br><br>
</body>
</html>
